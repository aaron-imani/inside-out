INFERENCE_PORT=49999
INFERENCE_URL=http://YOUR_INFERENCE_URL:${INFERENCE_PORT}/v1
USE_OPEN_SOURCE=1
OLLM_SERVER_TYPE=vllm
MODEL_TEMPERATURE=0

# MODEL_NAME=o1-2024-12-17

MAX_TOTAL_NUM_TOKENS=15919

# MODEL_NAME=Qwen/Qwen2.5-Coder-32B-Instruct-AWQ
# MODEL_NAME=Qwen/Qwen2.5-32B-Instruct-AWQ
MODEL_NAME=Qwen/QwQ-32B-AWQ